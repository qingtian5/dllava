## ğŸ› ï¸ å¿«é€Ÿä¸Šæ‰‹

### æ¨ç†
- å‚è€ƒscripts/inference.sh


### è®­ç»ƒ
- xtuner train <job_name>
#### mindgpt2.0
- å‚è€ƒ scripts/lizrun_moe.sh
<!-- - å‚è€ƒlizrun.sh
- ä»»åŠ¡è¶…å‚æ•°è°ƒæ•´è·¯å¾„ xtuner/configs/llava/~/finetune(pretrain)/~.py
- æ¯”å¦‚ï¼Œjob_name = llava_internlm2_chat_20b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetuneï¼Œåˆ™åº”è¯¥ç¼–è¾‘xtuner/configs/llava/internlm2_chat_20b_clip_vit_large_p14_336/finetune/llava_internlm2_chat_20b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune.py
- ç›®å‰å®éªŒè¿‡çš„æ‰€æœ‰llm, visual encoderç»„åˆéƒ½å¯ä»¥åœ¨è·¯å¾„ä¸­æ‰¾åˆ° -->

#### å¸¸ç”¨è®­ç»ƒé›†
- image_folder: /mnt/pfs-guan-ssai/cv/yanghongfu/xtuner-main/data/llava_data/llava_images
##### pretrain
- bcs558k: /mnt/pfs-guan-ssai/cv/moxu/xtuner-main/data/llava_data/LLaVA-Pretrain/blip_laion_cc_sbu_558k.json 

##### finetune
- mix665k: /mnt/pfs-guan-ssai/cv/moxu/xtuner-main/data/llava_data/LLaVA-Instruct-150K/llava_v1_5_mix665k.json

#### å¼€å§‹è®­ç»ƒ
- lizrun start -c lizrun.sh -n 1 -i reg-ai.chehejia.com/ssai/lizr/cu120/py310/pytorch:2.2.1-xtuner

#### pth_to_hf
- xtuner convert pth_to_hf <job_name> <./epoch_~.pth> <./epoch_~_hf>

### è¯„æµ‹
**TODO: VLMEVAL**
- xtuner mmbench <llm_path> --visual-encoder <vit_path> --prompt-template <> --data-path <~.tsv> --work-dir <> --llava <./epoch_~_hf>
- prompt template è¯·å’Œè®­ç»ƒæ—¶çš„å‚æ•°é…ç½®ä¿æŒä¸€è‡´
- work-dir ç»“æœä¿å­˜è·¯å¾„
- tsvè¯„æµ‹æ–‡ä»¶
- mingpt2.0ï¼Œå‚è€ƒä»¥ä¸‹ä»£ç 
```
xtuner mmbench  /mnt/pfs-mc0p4k/cv/team/yanghongfu/mindgpt3ov/models/sft-mind-gpt-v7moe-1010_dpo_dpo-0923_2560_n12b3e2_1010-seed42-ckpt-3354 \
--visual-encoder /mnt/pfs-mc0p4k/cv/team/yanghongfu/mindgpt3ov/models/siglip-so400m-patch14-384 \
--dino-visual-encoder /mnt/pfs-mc0p4k/cv/team/yanghongfu/mindgpt3ov/models/dinov2-large \
--llava /mnt/pfs-mc0p4k/cv/team/yanghongfu/work_dirs/llava_mindgpt_moe_siglipdino_lora_e1_gpu8_finetune_multisubimages/sft-mindgpt-v7moe-siglipdino-448-sw-minimonkey-img-slice-300m-stage2-cambrian-cauldron-great-intergration-50m-ft_iter_13900_hf \
--prompt-template mindgpt \
--data-path /mnt/pfs-mc0p4k/cv/team/zhanghongyuan/mindgpt-v-yanghongfu/eval_tsv/MMBench_DEV_EN.tsv \
--dynamic-image-size 448 \
--num-sub-images 6 \
--projector-num-queries 256 64 \
--work-dir /mnt/pfs-mc0p4k/cv/team/zhanghongyuan/mindgpt-v-yanghongfu/workdirs/1234
```

```
  'MMBench_DEV_EN': "https://opencompass.openxlab.space/utils/VLMEval/MMBench_DEV_EN.tsv", 
  'MMBench_TEST_EN': "https://opencompass.openxlab.space/utils/VLMEval/MMBench_TEST_EN.tsv", 
  'MMBench_DEV_CN': "https://opencompass.openxlab.space/utils/VLMEval/MMBench_DEV_CN.tsv", 
  'MMBench_TEST_CN': "https://opencompass.openxlab.space/utils/VLMEval/MMBench_TEST_CN.tsv", 
  'CCBench': "https://opencompass.openxlab.space/utils/VLMEval/CCBench.tsv", 
  'MME': "https://opencompass.openxlab.space/utils/VLMEval/MME.tsv", 
  'SEEDBench_IMG': "https://opencompass.openxlab.space/utils/VLMEval/SEEDBench_IMG.tsv", 
```

### å¾®è°ƒ [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QAEZVBfQ7LZURkMUtaq0b-5nEQII9G9Z?usp=sharing)

XTuner æ”¯æŒå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ã€‚æ•°æ®é›†é¢„å¤„ç†æŒ‡å—è¯·æŸ¥é˜…[æ–‡æ¡£](./docs/zh_cn/user_guides/dataset_prepare.md)ã€‚

  ```shell
  # å•å¡
  xtuner train internlm2_chat_7b_qlora_oasst1_e3 --deepspeed deepspeed_zero2
  # å¤šå¡
  (DIST) NPROC_PER_NODE=${GPU_NUM} xtuner train internlm2_chat_7b_qlora_oasst1_e3 --deepspeed deepspeed_zero2
  ```

  - `--deepspeed` è¡¨ç¤ºä½¿ç”¨ [DeepSpeed](https://github.com/microsoft/DeepSpeed) ğŸš€ æ¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚XTuner å†…ç½®äº†å¤šç§ç­–ç•¥ï¼ŒåŒ…æ‹¬ ZeRO-1ã€ZeRO-2ã€ZeRO-3 ç­‰ã€‚å¦‚æœç”¨æˆ·æœŸæœ›å…³é—­æ­¤åŠŸèƒ½ï¼Œè¯·ç›´æ¥ç§»é™¤æ­¤å‚æ•°ã€‚

  - æ›´å¤šç¤ºä¾‹ï¼Œè¯·æŸ¥é˜…[æ–‡æ¡£](./docs/zh_cn/user_guides/finetune.md)ã€‚

- **æ­¥éª¤ 2**ï¼Œå°†ä¿å­˜çš„ PTH æ¨¡å‹ï¼ˆå¦‚æœä½¿ç”¨çš„DeepSpeedï¼Œåˆ™å°†ä¼šæ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼‰è½¬æ¢ä¸º HuggingFace æ¨¡å‹ï¼š

  ```shell
  xtuner convert pth_to_hf ${CONFIG_NAME_OR_PATH} ${PTH} ${SAVE_PATH}
  ```
